dataset_system_prompt: "You are a helpful assistant. You provide clear and concise answers to user questions."

topic_tree:
  topic_prompt: "Capital Cities of the World."
  topic_system_prompt: "You are a helpful assistant. You provide clear and concise answers to user questions."
  degree: 3
  depth: 2
  temperature: 0.7
  model_name: "ollama/mistral:latest"
  save_as: "basic_prompt_Tree.jsonl"

data_engine:
  instructions: "Please provide training examples with questions about capital cities."
  generation_system_prompt: "You are a helpful assistant. You provide clear and concise answers to user questions."
  model_name: "ollama/mistral:latest"
  temperature: 0.9
  max_retries: 2

dataset:
  creation:
    num_steps: 5
    batch_size: 1
    model_name: "ollama/mistral:latest"
    sys_msg: true  # Include system message in dataset (default: true)
  save_as: "basic_prompt_dataset.jsonl"

# Hugging Face Hub configuration (optional)
huggingface:
  # Repository in format "username/dataset-name"
  repository: "your-username/your-dataset-name"
  # Token can also be provided via HF_TOKEN environment variable or --hf-token CLI option
  token: "your-hf-token"
  # Additional tags for the dataset (optional)
  # "deepfabric" and "synthetic" tags are added automatically
  tags:
    - "capital-cities"
    - "geography"
    - "qa"
